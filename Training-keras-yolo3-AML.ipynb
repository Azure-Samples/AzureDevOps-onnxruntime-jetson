{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Download the model weights from original Darket's release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# TODO:\n",
    "1. remove hardcoded filenames from `train_aml.py` and `train.py`\n",
    "2. cleanup `model_data` folder to reduce size\n",
    "3. upload `*.weights` to model registry to reduce size for aml/staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.2.4\n",
      "  Using cached Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement onnxruntime==1.4.0 (from versions: none)\n",
      "ERROR: No matching distribution found for onnxruntime==1.4.0\n",
      "WARNING: You are using pip version 20.2.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the 'C:\\ProgramData\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\magoswam\\appdata\\roaming\\python\\python37\\site-packages (1.15.2)\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (7.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (3.2.2)\n",
      "Requirement already satisfied: h5py in c:\\users\\magoswam\\appdata\\roaming\\python\\python37\\site-packages (2.10.0)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\magoswam\\appdata\\roaming\\python\\python37\\site-packages (1.15.0)\n",
      "Collecting azureml-sdk\n",
      "  Using cached azureml_sdk-1.13.0-py3-none-any.whl (4.4 kB)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.2.4 tensorflow pillow matplotlib h5py tensorboard azureml-sdk onnxruntime==1.4.0 onnx==1.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+git://github.com/microsoft/onnxconverter-common.git@3451bbffe61a2591a17f4d99a405b48e9ae8e395\n",
    "    \n",
    "!pip install git+git://github.com/onnx/keras-onnx.git@ff17787c393e2ce34d43185447d7354525f3ba87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599866329364
    }
   },
   "outputs": [],
   "source": [
    "# setting the model variables\n",
    "\n",
    "yolo3_keras_model = 'model_data/tiny_yolo_weights.h5' # need to pass this as parameter to train.py\n",
    "yolo3_weights_filename = 'model_data/yolo_v3-tiny.weights' # remove this from model_data after the keras conversion\n",
    "yolo3_config = 'model_data/yolov3-tiny.cfg'\n",
    "model_url = 'https://pjreddie.com/media/files/yolov3-tiny.weights'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the model\n",
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(model_url, yolo3_weights_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Convert the Darket model to Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1599686892988
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# execute the pre-built conversion script provided in the sample\n",
    "!python3  .src/convert.py $yolo3_config $yolo3_weights_filename $yolo3_keras_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Training data\n",
    "This sample uses the [VOC Pascal dataset](http://host.robots.ox.ac.uk/pascal/VOC/voc2007/#devkit) referred to as _VOCDevkit_.\n",
    "\n",
    "To generate your own annotation file and class names file.\n",
    "\n",
    "- One row for one image;  \n",
    "- Row format: `image_file_path box1 box2 ... boxN`;  \n",
    "- Box format: `x_min,y_min,x_max,y_max,class_id` (no space).  \n",
    "- For VOC dataset, try `python voc_annotation.py`  \n",
    "Here is an example:\n",
    "\n",
    "        ```\n",
    "        path/to/img1.jpg 50,100,150,200,0 30,50,200,120,3\n",
    "        path/to/img2.jpg 120,300,250,600,2\n",
    "        ...\n",
    "        ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1599850448344
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# setup the folder for the training dataset\n",
    "\n",
    "import os\n",
    "\n",
    "dataset_folder = 'training_dataset'\n",
    "dataset_filename = dataset_folder + '/VOCtrainval2007.tar'\n",
    "optional_dataset_filename = dataset_folder + '/VOCtest2007.tar'\n",
    "\n",
    "if not os.path.exists(dataset_folder):\n",
    "    os.makedirs(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1599800954418
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "dataset_url = 'http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar'\n",
    "urllib.request.urlretrieve(dataset_url, dataset_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1599800992283
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "optional_dataset_url = 'http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar'\n",
    "urllib.request.urlretrieve(optional_dataset_url, optional_dataset_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Unpack the dataset and prepare to upload to Datastore in AML.\n",
    "\n",
    "_This step will take a few minutes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "! tar xf $dataset_filename\n",
    "! tar xf $optional_dataset_filename\n",
    "! python ./voc_annotation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1600229184624
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Initialize Workspace \n",
    "from azureml.core import Workspace\n",
    "\n",
    "## existing AML Workspace in config.json\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n",
    "\n",
    "def_blob_store = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### OR create a new workspace with the following steps\n",
    "\n",
    "```\n",
    "from azureml.core import Workspace\n",
    "\n",
    "### Change this cell from markdown to code and run this if you need to create a workspace \n",
    "### Update the values for your workspace below\n",
    "ws=Workspace.create(subscription_id=\"<subscription-id goes here>\",\n",
    "                resource_group=\"<resource group goes here>\",\n",
    "                name=\"<name of the AML workspace>\",\n",
    "                location=\"<location>\")\n",
    "                \n",
    "ws.write_config()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Upload the VOCdevkit to the workspace datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1599952928985
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def_blob_store.upload(\"VOCdevkit\", target_path=\"/data/VOCdevkit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Train the Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1600230579551
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "#set the project folder\n",
    "PROJECT_FOLDER = \"./aml/staging\"\n",
    "if os.path.exists(PROJECT_FOLDER):\n",
    "    shutil.rmtree(PROJECT_FOLDER)\n",
    "\n",
    "os.makedirs(PROJECT_FOLDER, exist_ok=True)\n",
    "\n",
    "# copy all python scripts to project folder\n",
    "files = glob.glob(\"*.py\")\n",
    "for f in files:\n",
    "    shutil.copy(f, PROJECT_FOLDER)\n",
    "\n",
    "# copy all config files to the project folder\n",
    "files = glob.glob(\"*.cfg\")\n",
    "for f in files:\n",
    "    shutil.copy(f, PROJECT_FOLDER)\n",
    "\n",
    "# copy all text files to the project folder\n",
    "files = glob.glob(\"*.txt\")\n",
    "for f in files:\n",
    "    shutil.copy(f, PROJECT_FOLDER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1600230590565
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "! cp -rf model_data $PROJECT_FOLDER # copy the dataset under the project folder\n",
    "\n",
    "!cp -rf yolo3 $PROJECT_FOLDER # copy the model files under the project folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1600230593091
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.core import Dataset\n",
    "\n",
    "training_dataset = Dataset.File.from_files(path=(def_blob_store, '/data/VOCdevkit'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Add the optional packages and setup the training environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1600230597916
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_GPU_IMAGE\n",
    "\n",
    "cd = CondaDependencies.create(pip_packages=['keras==2.1.5', 'tensorflow==1.6.0', 'pillow', 'matplotlib', 'h5py', 'tensorboard'], conda_packages=['python=3.6.11'])\n",
    "myenv = Environment(\"yolov3\")\n",
    "myenv.python.conda_dependencies = cd\n",
    "myenv.python.conda_dependencies.add_pip_package(\"azureml-sdk\")\n",
    "myenv.python.conda_dependencies.add_channel(\"conda-forge\")\n",
    "myenv.docker.enabled = True\n",
    "myenv.docker.base_image = DEFAULT_GPU_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Setup the training compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1600230601716
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your CPU cluster\n",
    "CLUSTER_NAME = \"gpu-taining\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    aml_cluster = AmlCompute(workspace=ws, name=CLUSTER_NAME)\n",
    "    print(\"Found existing cluster, use it.\")\n",
    "except ComputeTargetException:\n",
    "    print(\"provisioning new compute target\")\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=\"STANDARD_NC6\", max_nodes=8, vm_priority=\"lowpriority\"\n",
    "    )\n",
    "    aml_cluster = ComputeTarget.create(ws, CLUSTER_NAME, compute_config)\n",
    "\n",
    "aml_cluster.wait_for_completion(show_output=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Define the run config for the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1600230606068
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "src = ScriptRunConfig(\n",
    "    source_directory=PROJECT_FOLDER,\n",
    "    script='train.py',\n",
    "    arguments=[\"--data\", training_dataset.as_named_input('input').as_mount()],\n",
    "    )\n",
    "\n",
    "src.run_config.framework = 'python'\n",
    "src.run_config.target = aml_cluster.name\n",
    "\n",
    "# Set environment\n",
    "src.run_config.environment = myenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Run the training experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1600230626434
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "EXPERIMENT_NAME = \"keras-yolo3\"\n",
    "\n",
    "experiment = Experiment(workspace=ws, name=EXPERIMENT_NAME)\n",
    "\n",
    "run = experiment.submit(config=src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1600234609822
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# register the model in the model registry\n",
    "\n",
    "my_trained_model = 'tiny_yolov3'\n",
    "\n",
    "from azureml.core import Model\n",
    "model = Model(ws, my_trained_model)\n",
    "\n",
    "# download the trainied model\n",
    "model.download(target_dir='model_data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Convert the model to ONNX and register in the model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "!pip uninstall -y tensorflow\n",
    "!pip install tensorflow==1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "!pip install tf2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1600274094449
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# install the Keras-to-ONNX converter dependent packages.\n",
    "# Installing from master branch to get the latest changes.\n",
    "!pip install git+https://github.com/onnx/keras-onnx.git@master \n",
    "!pip install git+https://github.com/microsoft/onnxconverter-common.git@master "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1600273274668
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "    # parser.add_argument('model_path', help='Path to Keras weights file.')\n",
    "    # parser.add_argument('anchors_path', help='Path to model achors file file.')\n",
    "    # parser.add_argument('onnx_filename', help='Path to converted ONNX model')\n",
    "    # parser.add_argument('target_opset', help='ONNX opset version')\n",
    "\n",
    "model_onnx = 'yolov3-tiny.onnx'\n",
    "\n",
    "!python3 ./convert2onnx.py 'model_data/tiny_yolo_weights.h5' 'model_data/tiny_yolo_anchors.txt' $model_onnx 11\n",
    "#!python3 ./convert2onnx.py 'model_data/trained_weights_final.h5' 'model_data/tiny_yolo_anchors.txt' $model_onnx 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Register the ONNX model in the workspace registry\n",
    "from azureml.core.model import Model\n",
    "Model.register(model_path = model_onnx, \n",
    "                model_name = \"yolo3.onnx\", \n",
    "                workspace = ws,\n",
    "                description=\"ONNX model converted from trained Keras/Tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# CLEANUP!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(PROJECT_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## FINISHED. \n",
    "Transition to the ADO to review status of the pipeline."
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
