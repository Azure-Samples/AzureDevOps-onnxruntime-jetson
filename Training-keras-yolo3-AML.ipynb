{"cells":[{"cell_type":"markdown","source":["### Download the model weights from original Darket's release"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["# TODO:\r\n","1. remove hardcoded filenames from `train_aml.py` and `train.py`\r\n","2. cleanup `model_data` folder to reduce size\r\n","3. upload `*.weights` to model registry to reduce size for aml/staging"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["# setting the model variables\r\n","import os\r\n","import urllib.request\r\n","\r\n","os.makedirs('model_data', exist_ok=True)\r\n","\r\n","yolo3_weights_filename ='model_data/yolov3-tiny.weights' # remove this from model_data after the keras conversion\r\n","yolo3_config = 'keras-yolo3/yolov3-tiny.cfg'\r\n","model_url = 'https://pjreddie.com/media/files/yolov3-tiny.weights'"],"outputs":[],"execution_count":null,"metadata":{"gather":{"logged":1600399561711}}},{"cell_type":"code","source":["# download the model weights\r\n","urllib.request.urlretrieve(model_url, yolo3_weights_filename)"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600399648147}}},{"cell_type":"markdown","source":["## Install dependent packages"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["!pip uninstall -y azureml-automl-runtime azureml-train-automl-runtime\r\n","!pip install -U keras==2.2.4 tensorflow==1.14.0 tensorflow-gpu==1.14.0 pillow matplotlib h5py==2.10.0 tensorboard azureml-sdk==1.13.0 onnxruntime==1.4.0 onnx==1.7.0 azureml-widgets azureml-tensorboard azureml-opendatasets azureml-mlflow azureml-defaults azureml-contrib-services azureml-contrib-interpret\r\n","\r\n","!pip install -U git+git://github.com/microsoft/onnxconverter-common.git@3451bbffe61a2591a17f4d99a405b48e9ae8e395\r\n","!pip install -U git+git://github.com/onnx/keras-onnx.git@ff17787c393e2ce34d43185447d7354525f3ba87"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600399672349}}},{"cell_type":"markdown","source":["### Convert the Darket model to Keras"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["yolo3_keras_model = 'model_data/tiny_yolo_weights.h5' # Converted from the Darknet weights. Need to pass this as parameter to train.py\r\n","\r\n","# execute the pre-built conversion script provided in the sample\r\n","!python3 keras-yolo3/convert.py $yolo3_config $yolo3_weights_filename $yolo3_keras_model"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600399686661}}},{"cell_type":"markdown","source":["### Training data\r\n","This sample uses the [VOC Pascal dataset](http://host.robots.ox.ac.uk/pascal/VOC/voc2007/#devkit) referred to as _VOCDevkit_.\r\n","\r\n","To generate your own annotation file and class names file.\r\n","\r\n","- One row for one image;  \r\n","- Row format: `image_file_path box1 box2 ... boxN`;  \r\n","- Box format: `x_min,y_min,x_max,y_max,class_id` (no space).  \r\n","- For VOC dataset, try `python voc_annotation.py`  \r\n","Here is an example:\r\n","\r\n","        ```\r\n","        path/to/img1.jpg 50,100,150,200,0 30,50,200,120,3\r\n","        path/to/img2.jpg 120,300,250,600,2\r\n","        ...\r\n","        ```"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["# setup the folder for the training dataset\r\n","\r\n","import os\r\n","\r\n","dataset_folder = '/mnt/tmp/'\r\n","os.makedirs(dataset_folder, exist_ok=True)\r\n","\r\n","dataset_filename = dataset_folder + 'VOCtrainval2007.tar'\r\n","optional_dataset_filename = dataset_folder + 'VOCtest2007.tar'"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600399687004}}},{"cell_type":"code","source":["dataset_url = 'http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar'\r\n","urllib.request.urlretrieve(dataset_url, dataset_filename)"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600399746454}}},{"cell_type":"code","source":["optional_dataset_url = 'http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar'\r\n","urllib.request.urlretrieve(optional_dataset_url, optional_dataset_filename)"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600399801009}}},{"cell_type":"markdown","source":["Unpack the dataset and prepare to upload to Datastore in AML.\r\n","\r\n","_This step will take a few minutes._"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["! tar xf $dataset_filename -C $dataset_folder\r\n","! tar xf $optional_dataset_filename -C $dataset_folder"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600312612293}}},{"cell_type":"markdown","source":["Convert VOC-style dataset to YOLO-style dataset"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["! python src/voc_annotation.py"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["%%writefile config.json\r\n","{\r\n","    \"workspace_name\": \"\",\r\n","    \"subscription_id\": \"\",\r\n","    \"resource_group\": \"\",\r\n","    \"location\": \"\"\r\n","}"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["#Initialize Workspace \r\n","from azureml.core import Workspace\r\n","\r\n","## existing AML Workspace in config.json\r\n","ws = Workspace.from_config()\r\n","print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\r\n","\r\n","def_blob_store = ws.get_default_datastore()"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600399806503}}},{"cell_type":"markdown","source":["#### OR create a new workspace with the following steps\r\n","\r\n","```\r\n","from azureml.core import Workspace\r\n","\r\n","### Change this cell from markdown to code and run this if you need to create a workspace \r\n","### Update the values for your workspace below\r\n","ws=Workspace.create(subscription_id=\"<subscription-id goes here>\",\r\n","                resource_group=\"<resource group goes here>\",\r\n","                name=\"<name of the AML workspace>\",\r\n","                location=\"<location>\")\r\n","                \r\n","ws.write_config()\r\n","```"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["Upload the VOCdevkit to the workspace datastore"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["def_blob_store.upload(dataset_folder + \"/VOCdevkit\", target_path=\"/data/VOCdevkit\", show_progress=False)"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600399936180}}},{"cell_type":"code","source":["from azureml.data.data_reference import DataReference\r\n","from azureml.core import Dataset\r\n","\r\n","training_dataset = Dataset.File.from_files(path=(def_blob_store, '/data/VOCdevkit'))"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600399940460}}},{"cell_type":"markdown","source":["### Train the Keras model."],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["import os\r\n","import shutil\r\n","import glob\r\n","\r\n","#set the project folder\r\n","PROJECT_FOLDER = \"./aml/staging\"\r\n","if os.path.exists(PROJECT_FOLDER):\r\n","    shutil.rmtree(PROJECT_FOLDER)\r\n","\r\n","os.makedirs(PROJECT_FOLDER, exist_ok=True)\r\n","\r\n","# copy all pythfrom keras-yolo3 repoject folder\r\n","files = glob.glob(\"keras-yolo3/*.py\")\r\n","for f in files:\r\n","    shutil.copy(f, PROJECT_FOLDER)\r\n","\r\n","# copy all config files to the project folder\r\n","files = glob.glob(\"keras-yolo3/*.cfg\")\r\n","for f in files:\r\n","    shutil.copy(f, PROJECT_FOLDER)\r\n","\r\n","# copy all text files to the project folder\r\n","files = glob.glob(\"keras-yolo3/*.txt\")\r\n","for f in files:\r\n","    shutil.copy(f, PROJECT_FOLDER)\r\n","\r\n","# copy all python scripts to project folder\r\n","files = glob.glob(\"src/*.py\")\r\n","for f in files:\r\n","    shutil.copy(f, PROJECT_FOLDER)"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600401213044}}},{"cell_type":"code","source":["! cp -rf keras-yolo3/model_data $PROJECT_FOLDER # copy the dataset under the project folder\r\n","\r\n","! cp -rf keras-yolo3/yolo3 $PROJECT_FOLDER # copy the model files under the project fold er"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600401213925}}},{"cell_type":"code","source":["# copy the Keras model files to PROJECT FOLDER\n","files = glob.glob(\"model_data/*.*\")\n","for f in files:\n","    shutil.copy(f, PROJECT_FOLDER + '/model_data')"],"outputs":[],"execution_count":null,"metadata":{"gather":{"logged":1600401220707}}},{"cell_type":"markdown","source":["Add the optional packages and setup the training environment"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["from azureml.core import Environment\r\n","from azureml.core.conda_dependencies import CondaDependencies\r\n","from azureml.core.runconfig import DEFAULT_GPU_IMAGE\r\n","\r\n","cd = CondaDependencies.create(pip_packages=['keras==2.1.5', 'tensorflow==1.6.0', 'pillow', 'matplotlib', 'h5py', 'tensorboard'], conda_packages=['python=3.6.11'])\r\n","myenv = Environment(\"yolov3\")\r\n","myenv.python.conda_dependencies = cd\r\n","myenv.python.conda_dependencies.add_pip_package(\"azureml-sdk\")\r\n","myenv.python.conda_dependencies.add_channel(\"conda-forge\")\r\n","myenv.docker.enabled = True\r\n","myenv.docker.base_image = DEFAULT_GPU_IMAGE"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600399946123}}},{"cell_type":"markdown","source":["Setup the training compute"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["from azureml.core.compute import ComputeTarget, AmlCompute\r\n","from azureml.core.compute_target import ComputeTargetException\r\n","\r\n","# Choose a name for my cluster\r\n","CLUSTER_NAME = \"gpu-taining\"\r\n","\r\n","# Verify that cluster does not exist already\r\n","try:\r\n","    aml_cluster = AmlCompute(workspace=ws, name=CLUSTER_NAME)\r\n","    print(\"Found existing cluster, use it.\")\r\n","except ComputeTargetException:\r\n","    print(\"provisioning new compute target\")\r\n","    compute_config = AmlCompute.provisioning_configuration(\r\n","        vm_size=\"STANDARD_NC6\", max_nodes=8, vm_priority=\"lowpriority\", idle_seconds_before_scaledown=1800\r\n","    )\r\n","    aml_cluster = ComputeTarget.create(ws, CLUSTER_NAME, compute_config)\r\n","\r\n","aml_cluster.wait_for_completion(show_output=True)\r\n"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600399946531}}},{"cell_type":"markdown","source":["Define the run config for the experiment"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["from azureml.core import ScriptRunConfig\r\n","\r\n","src = ScriptRunConfig(\r\n","    source_directory=PROJECT_FOLDER,\r\n","    script='train_aml.py',\r\n","    arguments=[\"--data\", training_dataset.as_named_input('input').as_mount()],\r\n","    )\r\n","\r\n","src.run_config.framework = 'python'\r\n","src.run_config.target = aml_cluster.name\r\n","\r\n","# Set environment\r\n","src.run_config.environment = myenv"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600399946889}}},{"cell_type":"markdown","source":["Run the training experiment"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["from azureml.core import Experiment\r\n","\r\n","EXPERIMENT_NAME = \"keras-yolo3\"\r\n","\r\n","experiment = Experiment(workspace=ws, name=EXPERIMENT_NAME)\r\n","\r\n","run = experiment.submit(config=src)"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600401252425}}},{"cell_type":"code","source":["%%time\r\n","\r\n","run.wait_for_completion(show_output=True)"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["# register the model in the model registry\r\n","\r\n","my_trained_model = 'tiny_yolov3'\r\n","\r\n","from azureml.core import Model\r\n","model = Model(ws, my_trained_model)\r\n","\r\n","# download the trainied model\r\n","model.download(target_dir='model_data', exist_ok=True)"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600401461560}}},{"cell_type":"markdown","source":["### Convert the model to ONNX and register in the model registry"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["trained_model_path=\"model_data/trained_weights_final.h5\" # make sure this name matches the downloaded file is the previous step\r\n","test_image=dataset_folder + \"VOCdevkit/VOC2007/JPEGImages/000001.jpg\"\r\n","anchors_path=\"model_data/tiny_yolo_anchors.txt\"\r\n","classes_path=\"model_data/voc_classes.txt\"\r\n","onnx_model_file=\"model_data/new_yolo.onnx\"\r\n","\r\n","!python ./src/convert2onnx.py \\\r\n","    --model_path $trained_model_path \\\r\n","    --test_image $test_image \\\r\n","    --anchors_path $anchors_path \\\r\n","    --classes_path $classes_path \\\r\n","    --model_file_name $onnx_model_file \\\r\n","    --overwrite"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600401491079}}},{"cell_type":"markdown","source":["Test this ONNX Model"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["%matplotlib inline\r\n","import matplotlib.pyplot as plt\r\n","from PIL import Image\r\n","\r\n","image = Image.open(dataset_folder + \"VOCdevkit/VOC2007/JPEGImages/000001.jpg\")\r\n","image_score = Image.open(dataset_folder + \"VOCdevkit/VOC2007/JPEGImages/000001_score.jpg\")\r\n","fig, ax = plt.subplots(1,2)\r\n","ax[0].imshow(image)\r\n","ax[1].imshow(image_score)\r\n","ax[0].axis('off')\r\n","_ = ax[1].axis('off')"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600401491786}}},{"cell_type":"code","source":["# Register the ONNX model in the workspace registry\r\n","from azureml.core.model import Model\r\n","Model.register(model_path = onnx_model_file, \r\n","                model_name = \"TinyYOLO\", \r\n","                workspace = ws,\r\n","                description=\"ONNX model converted from trained Keras/Tf\")"],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1600401492778}}},{"cell_type":"markdown","source":["# CLEANUP!!!"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["Optionally remove all the files downloaded for this exercise.\r\n","\r\n","```\r\n","shutil.rmtree(PROJECT_FOLDER)\r\n","shutil.rmtree('/tmp/VOCdevkit')\r\n","\r\n","files = glob.glob(\"aml\")\r\n","for f in files:\r\n","    os.remove(f)\r\n","```"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["## FINISHED. \r\n","Transition to the ADO to review status of the pipeline."],"metadata":{"nteract":{"transient":{"deleting":false}}}}],"metadata":{"kernelspec":{"name":"python3-azureml","language":"python","display_name":"Python 3.6 - AzureML"},"language_info":{"name":"python","version":"3.6.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernel_info":{"name":"python3-azureml"},"nteract":{"version":"nteract-front-end@1.0.0"}},"nbformat":4,"nbformat_minor":2}